{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the relevant weeks of data from CSV files (there is one for each week including every journey made during that week) and merges it with data on the location of each docking station in order to explore further in Tableau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data on the bike docking stations\n",
    "bike_locations_import = pd.read_csv(\"bike_locations_extra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "# function to combine docking station data with journey data and export to CSV\n",
    "for i in range(212,217):\n",
    "    print(i)\n",
    "    trip_data_import = pd.read_csv(\"C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/All bike wweeks/\"+str(i)+\".csv\")\n",
    "    trip_data_import.head()\n",
    "    merged_data = trip_data_import.merge(bike_locations_import, \n",
    "                left_on='StartStation Id', right_on=\"Dock_ID\", how='left').merge(bike_locations_import, \n",
    "                left_on=\"EndStation Id\", right_on=\"Dock_ID\",\n",
    "                how='left',suffixes=('_start', '_end'))\n",
    "\n",
    "    merged_data = merged_data[[\"Dock_ID_end\", \"Dock_ID_start\",\"Start Date\", \"End Date\",\"Duration\",\"latitude_x_start\", \"longitude_x_start\",\n",
    "                              \"latitude_x_end\", \"longitude_x_end\", \n",
    "                              \"description_code_x_start\", 'description_code_x_end']]\n",
    "\n",
    "    merged_data.columns = [\"start_dock\", \"end_dock\",\"start_date\", \"end_date\",\"duration\", \"lat_start\", \"lon_start\", \n",
    "                           \"lat_end\", \"lon_end\", \"area_start\", \"area_end\"]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    merged_data = merged_data.dropna()\n",
    "    merged_data = merged_data.reset_index(drop=True)\n",
    "    \n",
    "    merged_data.to_csv(\"merged_data_dock_\"+str(i)+\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_may = pd.read_csv(\"merged_data_dock_May_2019_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area End       object\n",
       "Area Start     object\n",
       "End Date       object\n",
       "Start Date     object\n",
       "Table Name     object\n",
       "Duration        int64\n",
       "End Dock        int64\n",
       "F1              int64\n",
       "Lat End       float64\n",
       "Lat Start     float64\n",
       "Lon End       float64\n",
       "Lon Start     float64\n",
       "Start Dock      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_may.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_may[\"Start Date\"]=pd.to_datetime(data_may[\"Start Date\"])\n",
    "data_may[\"End Date\"]=pd.to_datetime(data_may[\"End Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_may[\"start_year\"]=data_may[\"Start Date\"].apply(lambda x: x.year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020=data_may[data_may[\"start_year\"]==2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972897, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019= data_may[data_may[\"start_year\"]==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639685, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export which includes more information\n",
    "end_2020 = data_2020.groupby(by=[\"End Dock\"]).size().reset_index().to_csv(\"end_dock_May_20.csv\")\n",
    "start_2020 = data_2020.groupby(by=[\"Start Dock\"]).size().reset_index().to_csv(\"start_dock_May_20.csv\")\n",
    "end_2019 = data_2019.groupby(by=[\"End Dock\"]).size().reset_index().to_csv(\"end_dock_May_19.csv\")\n",
    "start_2019 = data_2019.groupby(by=[\"Start Dock\"]).size().reset_index().to_csv(\"start_dock_May_19.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
